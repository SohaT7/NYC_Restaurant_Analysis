{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3067f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0af54476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1810ca2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBA</th>\n",
       "      <th>STREET</th>\n",
       "      <th>INCOME_LEVEL</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>CUISINE_DESCRIPTION</th>\n",
       "      <th>SCORE</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PATHOS</td>\n",
       "      <td>1 AVENUE</td>\n",
       "      <td>high income</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10022</td>\n",
       "      <td>Mediterranean</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>THE LITTLE BEET</td>\n",
       "      <td>PARK AVENUE</td>\n",
       "      <td>high income</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10017</td>\n",
       "      <td>Salads</td>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMAZE FUSION &amp; LOUNGE</td>\n",
       "      <td>3 AVENUE</td>\n",
       "      <td>high income</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10017</td>\n",
       "      <td>Asian/Asian Fusion</td>\n",
       "      <td>27</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOURISH THAI</td>\n",
       "      <td>VANDERBILT AVENUE</td>\n",
       "      <td>medium income</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11238</td>\n",
       "      <td>Thai</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESSEN</td>\n",
       "      <td>MADISON AVENUE</td>\n",
       "      <td>high income</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>10017</td>\n",
       "      <td>Sandwiches</td>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     DBA             STREET   INCOME_LEVEL    BOROUGH  \\\n",
       "0                 PATHOS           1 AVENUE    high income  Manhattan   \n",
       "1        THE LITTLE BEET        PARK AVENUE    high income  Manhattan   \n",
       "2  AMAZE FUSION & LOUNGE           3 AVENUE    high income  Manhattan   \n",
       "3           NOURISH THAI  VANDERBILT AVENUE  medium income   Brooklyn   \n",
       "4                  ESSEN     MADISON AVENUE    high income  Manhattan   \n",
       "\n",
       "   ZIPCODE CUISINE_DESCRIPTION  SCORE GRADE  \n",
       "0    10022       Mediterranean      9     A  \n",
       "1    10017              Salads     13     A  \n",
       "2    10017  Asian/Asian Fusion     27     B  \n",
       "3    11238                Thai      9     A  \n",
       "4    10017          Sandwiches     13     A  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our input dataset\n",
    "\n",
    "# Load the file\n",
    "file_path = Path('FINAL_NYC_restaurants_full_database.csv')\n",
    "# Read into a dataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "# Show dataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54dcc5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['DBA', 'STREET', 'INCOME_LEVEL', 'BOROUGH', 'ZIPCODE', 'CUISINE_DESCRIPTION'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d1a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE     int64\n",
      "GRADE    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea3b5c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE</th>\n",
       "      <th>GRADE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCORE GRADE\n",
       "0      9     A\n",
       "1     13     A\n",
       "2     27     B\n",
       "3      9     A\n",
       "4     13     A"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0794851b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    7033\n",
       "B     691\n",
       "C     222\n",
       "P     138\n",
       "Z      90\n",
       "N      50\n",
       "Name: GRADE, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine different grades under 'GRADE' column\n",
    "df['GRADE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfc8f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the grades 'N', 'P', and 'Z'\n",
    "df.drop(df[(df['GRADE'] == 'N') | (df['GRADE'] == 'P') | (df['GRADE'] == 'Z')].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f708a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    7033\n",
       "B     691\n",
       "C     222\n",
       "Name: GRADE, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine different grades under 'GRADE' column\n",
    "df['GRADE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc894ed",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09243dbb",
   "metadata": {},
   "source": [
    "## Normalizing the Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95aa9c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRADE    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Generate our categorical variable list\n",
    "df_cat = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "df[df_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a91c6",
   "metadata": {},
   "source": [
    "## Encoding the Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4492805",
   "metadata": {},
   "source": [
    "### Encoding the variable 'GRADE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f93fa640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCORE GRADE  Grade\n",
       "0      9     A      0\n",
       "1     13     A      0\n",
       "2     27     B      1\n",
       "3      9     A      0\n",
       "4     13     A      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a 'high' and 'low' grade\n",
    "\n",
    "# Creating an instance of label encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"Grade\"] = label_encoder.fit_transform(df[\"GRADE\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3258a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade dictionary\n",
    "## The dictionary creates two categories for grades: \"high\" and \"low\".\n",
    "## \"high\" grade has been made to replace grades A and B, \n",
    "## whereas \"low\" grade has been made to replace all grades lower than A and B.\n",
    "\n",
    "GRADE_num = {\n",
    "    \"A\": \"high\",\n",
    "    \"B\": \"high\",\n",
    "    \"C\": \"low\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2671c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>Grade</th>\n",
       "      <th>GRADE_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>B</td>\n",
       "      <td>1</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCORE GRADE  Grade GRADE_num\n",
       "0      9     A      0      high\n",
       "1     13     A      0      high\n",
       "2     27     B      1      high\n",
       "3      9     A      0      high\n",
       "4     13     A      0      high"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grades encoded using the dictionary values\n",
    "df[\"GRADE_num\"] = df[\"GRADE\"].apply(lambda x: GRADE_num[x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0190014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE</th>\n",
       "      <th>GRADE_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCORE GRADE_num\n",
       "0      9      high\n",
       "1     13      high\n",
       "2     27      high\n",
       "3      9      high\n",
       "4     13      high"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the GRADE and Grade columns\n",
    "df = df.drop([\"GRADE\", \"Grade\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0aca75c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRADE_num    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Generate our categorical variable list again\n",
    "df_cat = df.dtypes[df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column again\n",
    "df[df_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b51f5925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high    7724\n",
      "low      222\n",
      "Name: GRADE_num, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "GRADE_num_counts = df.GRADE_num.value_counts()\n",
    "print(GRADE_num_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ea1c00",
   "metadata": {},
   "source": [
    "### Encoding the Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a31cfe6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRADE_num_high</th>\n",
       "      <th>GRADE_num_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GRADE_num_high  GRADE_num_low\n",
       "0             1.0            0.0\n",
       "1             1.0            0.0\n",
       "2             1.0            0.0\n",
       "3             1.0            0.0\n",
       "4             1.0            0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(df[df_cat]))\n",
    "\n",
    "# Add the encoded variable names to the DataFrame\n",
    "encode_df.columns = enc.get_feature_names(df_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd35522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SCORE</th>\n",
       "      <th>GRADE_num_high</th>\n",
       "      <th>GRADE_num_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SCORE  GRADE_num_high  GRADE_num_low\n",
       "0      9             1.0            0.0\n",
       "1     13             1.0            0.0\n",
       "2     27             1.0            0.0\n",
       "3      9             1.0            0.0\n",
       "4     13             1.0            0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "df = df.merge(encode_df,left_index=True, right_index=True)\n",
    "df = df.drop(df_cat,1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de063c",
   "metadata": {},
   "source": [
    "## Splitting the Data, and Standardizing the Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "464ab95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove GRADE_num target from features data\n",
    "y = df.GRADE_num_high\n",
    "X = df.drop(columns=[\"GRADE_num_high\",\"GRADE_num_low\"])\n",
    "\n",
    "# Split training/test datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cda3b9",
   "metadata": {},
   "source": [
    "# Resampling Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac39bcfe",
   "metadata": {},
   "source": [
    "## Oversampling: Naive Random Oversampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbe0ef89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 5598, 0.0: 5598})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7b011fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11196,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e6c9d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9ce0b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38c1a936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive accuracy is: 0.517\n"
     ]
    }
   ],
   "source": [
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ddc1ac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive balanced accuracy is: 0.517\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "acc_score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive balanced accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75bcda9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30,  23],\n",
       "       [904, 963]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d942b9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.03      0.57      0.52      0.06      0.54      0.29        53\n",
      "        1.0       0.98      0.52      0.57      0.68      0.54      0.29      1867\n",
      "\n",
      "avg / total       0.95      0.52      0.56      0.66      0.54      0.29      1920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127073b",
   "metadata": {},
   "source": [
    "## Oversampling: SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d371963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 5598, 0.0: 5598})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTE\n",
    "from imblearn.over_sampling import SMOTE\n",
    "X_resampled, y_resampled = SMOTE(random_state=1, sampling_strategy='auto').fit_resample(\n",
    "    X_train_scaled, y_train\n",
    ")\n",
    "\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2428815a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11196,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4bb0075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8dcbae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa20deec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive accuracy is: 0.517\n"
     ]
    }
   ],
   "source": [
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "745db727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive balanced accuracy is: 0.517\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "acc_score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive balanced accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90b8add5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 30,  23],\n",
       "       [904, 963]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbca8322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.03      0.57      0.52      0.06      0.54      0.29        53\n",
      "        1.0       0.98      0.52      0.57      0.68      0.54      0.29      1867\n",
      "\n",
      "avg / total       0.95      0.52      0.56      0.66      0.54      0.29      1920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24f01ff",
   "metadata": {},
   "source": [
    "## Undersampling: Cluster Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "117d372c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 159, 1.0: 159})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the data using the ClusterCentroids resampler\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=1)\n",
    "X_resampled, y_resampled = cc.fit_resample(X_train_scaled, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec036909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(318,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b0b8110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "98d1e7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "97a293ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive accuracy is: 0.128\n"
     ]
    }
   ],
   "source": [
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8930b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive balanced accuracy is: 0.128\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "acc_score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive balanced accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1aa9c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  41,   12],\n",
       "       [1663,  204]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "598468f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.02      0.77      0.11      0.05      0.29      0.09        53\n",
      "        1.0       0.94      0.11      0.77      0.20      0.29      0.08      1867\n",
      "\n",
      "avg / total       0.92      0.13      0.76      0.19      0.29      0.08      1920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ec8d1d",
   "metadata": {},
   "source": [
    "## Combination (Over and Under) Sampling: SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3847b183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 805, 1.0: 630})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with SMOTEENN\n",
    "# Warning: This is a large dataset, and this step may take some time to complete\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=1)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X_train_scaled, y_train)\n",
    "Counter(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "087a53e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1435,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4c78d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Logistic Regression model using the resampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9c75ca7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f55b5029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive accuracy is: 0.028\n"
     ]
    }
   ],
   "source": [
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f73f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive balanced accuracy is: 0.028\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "acc_score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive balanced accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81ccc300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  53,    0],\n",
       "       [1867,    0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0378ad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.03      1.00      0.00      0.05      0.00      0.00        53\n",
      "        1.0       0.00      0.00      1.00      0.00      0.00      0.00      1867\n",
      "\n",
      "avg / total       0.00      0.03      0.97      0.00      0.00      0.00      1920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad3d3c",
   "metadata": {},
   "source": [
    "# Ensemble Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe1d532",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f89278a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "465d59e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 5598, 0.0: 159})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6aa5806e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5757,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6da66c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eeda9fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive accuracy is: 0.972\n"
     ]
    }
   ],
   "source": [
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "818115bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive balanced accuracy is: 0.972\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "acc_score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive balanced accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d336e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>0</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0            0           53\n",
       "Actual 1            0         1867"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5679faa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.00      0.00      1.00      0.00      0.00      0.00        53\n",
      "        1.0       0.97      1.00      0.00      0.99      0.00      0.00      1867\n",
      "\n",
      "avg / total       0.95      0.97      0.03      0.96      0.00      0.00      1920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b432785f",
   "metadata": {},
   "source": [
    "## Balanced Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "45428d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "# Create a balanced random forest classifier:\n",
    "brf_model = BalancedRandomForestClassifier(n_estimators=128, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "707a12b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 5598, 0.0: 159})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model:\n",
    "brf_model = brf_model.fit(X_train_scaled, y_train)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "314d13cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5757,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e920846f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions using the testing data:\n",
    "y_pred = brf_model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af8d9602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive accuracy is: 0.640\n"
     ]
    }
   ],
   "source": [
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26ab2ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive balanced accuracy is: 0.640\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "acc_score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive balanced accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "81ebfbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>658</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0           20           33\n",
       "Actual 1          658         1209"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e958a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.03      0.38      0.65      0.05      0.49      0.24        53\n",
      "        1.0       0.97      0.65      0.38      0.78      0.49      0.25      1867\n",
      "\n",
      "avg / total       0.95      0.64      0.38      0.76      0.49      0.25      1920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a3333e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 'SCORE')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "# Calculate feature importance in the Balanced Random Forest model.\n",
    "importances = brf_model.feature_importances_\n",
    "importances\n",
    "\n",
    "# We can sort the features by their importance.\n",
    "sorted(zip(brf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde36512",
   "metadata": {},
   "source": [
    "## Easy Ensemble AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "68c5a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the EasyEnsembleClassifier\n",
    "# Create a balanced random forest classifier:\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "ee_model = EasyEnsembleClassifier(n_estimators=128, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6fc4389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 5598, 0.0: 159})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model:\n",
    "ee_model = ee_model.fit(X_train_scaled, y_train)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "45b668a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5757,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "58cf6c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making predictions using the testing data:\n",
    "y_pred = ee_model.predict(X_test_scaled)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "21539fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive accuracy is: 0.629\n"
     ]
    }
   ],
   "source": [
    "# Calculated the accuracy score\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c10add16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This model's predictive balanced accuracy is: 0.629\n"
     ]
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "acc_score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\" This model's predictive balanced accuracy is: {accuracy_score(y_test,y_pred):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "884467d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>682</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0           23           30\n",
       "Actual 1          682         1185"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create a DataFrame from the confusion matrix.\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bac5d6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "        0.0       0.03      0.43      0.63      0.06      0.52      0.27        53\n",
      "        1.0       0.98      0.63      0.43      0.77      0.52      0.28      1867\n",
      "\n",
      "avg / total       0.95      0.63      0.44      0.75      0.52      0.28      1920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71bb20a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
